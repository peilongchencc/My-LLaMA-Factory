# å‘½ä»¤åˆ†æ

æœ¬ç« ä»‹ç»ä¸ºä»€ä¹ˆåœ¨å®‰è£…äº† LLaMA Factory åï¼Œç”¨æˆ·å¯ä»¥åœ¨ç»ˆç«¯æ“ä½œä½¿ç”¨ `llamafactory-cli` å‘½ä»¤ã€‚

- [å‘½ä»¤åˆ†æ](#å‘½ä»¤åˆ†æ)
  - [`llamafactory-cli` å‘½ä»¤å¯ä»¥ä½¿ç”¨çš„åŸå› :](#llamafactory-cli-å‘½ä»¤å¯ä»¥ä½¿ç”¨çš„åŸå› )
    - [`entry_points` çš„ä½œç”¨:](#entry_points-çš„ä½œç”¨)
      - [`setup.py` æ–‡ä»¶ä¸­çš„ `entry_points`:](#setuppy-æ–‡ä»¶ä¸­çš„-entry_points)
  - [æ‰§è¡Œ`pip install -e .`åå…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆ:](#æ‰§è¡Œpip-install--e-åå…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆ)
  - [æŒ‡ä»¤æ‰§è¡Œé€»è¾‘:](#æŒ‡ä»¤æ‰§è¡Œé€»è¾‘)
  - [`llamafactory/cli.py`æ–‡ä»¶æ³¨é‡Šç‰ˆ(å¯é€‰):](#llamafactoryclipyæ–‡ä»¶æ³¨é‡Šç‰ˆå¯é€‰)
    - [å…³é”®ç»„ä»¶:](#å…³é”®ç»„ä»¶)
  - [ä¸¾ä¾‹-ç»ˆç«¯è¿è¡Œ`llamafactory-cli help`:](#ä¸¾ä¾‹-ç»ˆç«¯è¿è¡Œllamafactory-cli-help)
  - [é™„å½•: sys.argv ç”¨æ³•è§£é‡Š](#é™„å½•-sysargv-ç”¨æ³•è§£é‡Š)


## `llamafactory-cli` å‘½ä»¤å¯ä»¥ä½¿ç”¨çš„åŸå› :

### `entry_points` çš„ä½œç”¨:

åœ¨ Python é¡¹ç›®ä¸­ï¼Œ`setup.py` æ–‡ä»¶ï¼ˆæˆ– `pyproject.toml` æ–‡ä»¶ï¼‰é€šå¸¸ç”¨äºå®šä¹‰å¦‚ä½•å®‰è£…å’Œé…ç½®è¿™ä¸ªåŒ…ã€‚`entry_points` æ˜¯ `setup.py` æ–‡ä»¶ä¸­çš„ä¸€ä¸ªé…ç½®é€‰é¡¹ï¼Œå®ƒå…è®¸ä½ å®šä¹‰å‘½ä»¤è¡Œå·¥å…·ï¼Œè¿™äº›å·¥å…·åœ¨å®‰è£…åå¯ä»¥ç›´æ¥ä»ç»ˆç«¯è°ƒç”¨ã€‚

#### `setup.py` æ–‡ä»¶ä¸­çš„ `entry_points`:

```python
entry_points={
    'console_scripts': [
        'llamafactory-cli=llamafactory.cli:main',
    ],
},
```

è¿™é‡Œçš„ `console_scripts` æ˜¯ä¸€ç±» `entry_points`ï¼Œç”¨äºå®šä¹‰ç»ˆç«¯å‘½ä»¤ã€‚æ¯ä¸ªç»ˆç«¯å‘½ä»¤é€šè¿‡ `'å‘½ä»¤å=æ¨¡å—è·¯å¾„:å‡½æ•°å'` çš„å½¢å¼å®šä¹‰ã€‚

> [!CAUTION]
> æ¨¡å—è·¯å¾„ä½¿ç”¨`.`ï¼Œé‡‡ç”¨çš„æ˜¯pythonæ¨¡å—å¯¼å…¥çš„æ ‡å‡†è¡¨ç¤ºæ³•ï¼Œå³ `import llamafactory.cli`ã€‚
> å¯»æ‰¾æŒ‡å®šæ¨¡å—ä¸­çš„åˆ¶å®šå¯¹è±¡(å‡½æ•°)æ—¶å›ºå®šè¦ç”¨å†’å·è¿›è¡Œåˆ†éš”ã€‚


## æ‰§è¡Œ`pip install -e .`åå…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆ:

å½“ä½¿ç”¨ `pip install -e .` å‘½ä»¤æ—¶ï¼Œ`setup.py` æ–‡ä»¶ä¸­å®šä¹‰çš„å‘½ä»¤è¡Œå·¥å…·ä¼šè¢«å®‰è£…åˆ°ç³»ç»Ÿçš„ PATH ä¸­ï¼Œä½¿å¾—å¯ä»¥ç›´æ¥åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ã€‚

å…·ä½“æ¥è¯´ï¼Œä¸‹åˆ—ä»£ç ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª **å¯æ‰§è¡Œæ–‡ä»¶** ã€‚è¿™æ˜¯ `pip` å¤„ç† `console_scripts` æ—¶çš„æ ‡å‡†è¡Œä¸º:

```python
entry_points={
    'console_scripts': [
        'llamafactory-cli=llamafactory.cli:main',
    ],
},
```

ç”Ÿæˆçš„ç»“æœå¯ä»¥é€šè¿‡ `which` æŒ‡ä»¤æŸ¥çœ‹ï¼Œä¾‹å¦‚:

```bash
# Linuxç³»ç»Ÿå¯ç”¨
which llamafactory-cli
```

ç»ˆç«¯æ•ˆæœ:

```log
(myenv) root@ubuntu22:/data/LLaMA-Factory-main# which llamafactory-cli
/home/vipuser/miniconda3/envs/myenv/bin/llamafactory-cli
```

ğŸ”¥çœ‹ç€æ˜¯ä¸æ˜¯å’Œ **pythonè§£é‡Šå™¨** å¾ˆåƒï¼Ÿæˆ‘ä»¬å†æ‰“å°ä¸€ä¸‹pythonè§£é‡Šå™¨çš„è·¯å¾„çœ‹ä¸€ä¸‹:

```log
(myenv) root@ubuntu22:/data/LLaMA-Factory-main# which llamafactory-cli
/home/vipuser/miniconda3/envs/myenv/bin/llamafactory-cli

(myenv) root@ubuntu22:/data/LLaMA-Factory-main# which python
/home/vipuser/miniconda3/envs/myenv/bin/python
```

çœ‹å‡ºæ¥äº†å§ï¼Œè¿™å…¶å®å°±æ˜¯ä¸€ä¸ª **pythonè§£é‡Šå™¨**ï¼Œåªæ˜¯è¿˜æœ‰ä¸€äº›é¢å¤–åŠŸèƒ½ã€‚ä¾‹å¦‚:

- å¯¼å…¥ `llamafactory.cli` æ¨¡å—
- æ‰§è¡Œ `main()` å‡½æ•°


## æŒ‡ä»¤æ‰§è¡Œé€»è¾‘:

å½“ä½ åœ¨ç»ˆç«¯è¾“å…¥ `llamafactory-cli` æ—¶ï¼š

1. **ç³»ç»Ÿæœç´¢è·¯å¾„**ï¼šç³»ç»Ÿä¼šæ£€æŸ¥æ‰€æœ‰åœ¨ `PATH` ç¯å¢ƒå˜é‡ä¸­çš„ç›®å½•ï¼Œå¯»æ‰¾åä¸º `llamafactory-cli` çš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚

2. **æ‰§è¡Œå¯æ‰§è¡Œæ–‡ä»¶**ï¼šæ‰¾åˆ°åï¼Œç³»ç»Ÿä¼šæ‰§è¡Œè¯¥æ–‡ä»¶ã€‚è¯¥æ–‡ä»¶å†…éƒ¨å®é™…ä¸Šæ˜¯è°ƒç”¨ Python è§£é‡Šå™¨ï¼Œè¿è¡Œç›¸åº”çš„æ¨¡å—å’Œå‡½æ•°ï¼Œå³ `llamafactory.cli:main`ã€‚æ‰¾åˆ° `llamafactory/cli.py` æ–‡ä»¶ï¼Œå¹¶æ‰§è¡Œé‡Œé¢çš„ `main()` å‡½æ•°ã€‚

3. **è¿è¡Œä»£ç **ï¼š`main()` å‡½æ•°ä¼šæ ¹æ®è¾“å…¥çš„å‚æ•°å†³å®šè¦æ‰§è¡Œçš„å…·ä½“é€»è¾‘ã€‚


## `llamafactory/cli.py`æ–‡ä»¶æ³¨é‡Šç‰ˆ(å¯é€‰):

è¯»è€…å¯ä»¥ç®€å•çœ‹ä¸€ä¸‹ `llamafactory/cli.py` æ–‡ä»¶ä¸­çš„ä»£ç é€»è¾‘ï¼Œæ–¹ä¾¿ç†è§£ä¹‹åçš„å†…å®¹ã€‚

```python
import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³çš„æ¨¡å—
import random  # å¯¼å…¥ç”Ÿæˆéšæœºæ•°çš„æ¨¡å—
import subprocess  # å¯¼å…¥æ‰§è¡Œå­è¿›ç¨‹çš„æ¨¡å—
import sys  # å¯¼å…¥ä¸Pythonè§£é‡Šå™¨äº¤äº’çš„æ¨¡å—
from enum import Enum, unique  # ä»enumæ¨¡å—å¯¼å…¥Enumç±»å’Œuniqueè£…é¥°å™¨

# å¯¼å…¥LLaMA Factoryé¡¹ç›®ä¸­çš„å…¶ä»–æ¨¡å—å’Œå‡½æ•°
from . import launcher  # å¯¼å…¥launcheræ¨¡å—
from .api.app import run_api  # å¯¼å…¥run_apiå‡½æ•°ï¼Œç”¨äºå¯åŠ¨APIæœåŠ¡å™¨
from .chat.chat_model import run_chat  # å¯¼å…¥run_chatå‡½æ•°ï¼Œç”¨äºå¯åŠ¨èŠå¤©æ¨¡å‹
from .eval.evaluator import run_eval  # å¯¼å…¥run_evalå‡½æ•°ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹
from .extras.env import VERSION, print_env  # å¯¼å…¥ç‰ˆæœ¬ä¿¡æ¯å’Œæ‰“å°ç¯å¢ƒä¿¡æ¯çš„å‡½æ•°
from .extras.logging import get_logger  # å¯¼å…¥æ—¥å¿—è®°å½•å™¨
from .extras.misc import get_device_count  # å¯¼å…¥è·å–è®¾å¤‡æ•°é‡çš„å‡½æ•°
from .train.tuner import export_model, run_exp  # å¯¼å…¥æ¨¡å‹å¯¼å‡ºå’Œå®éªŒè¿è¡Œçš„å‡½æ•°
from .webui.interface import run_web_demo, run_web_ui  # å¯¼å…¥å¯åŠ¨Webæ¼”ç¤ºå’ŒWeb UIçš„å‡½æ•°

# å®šä¹‰å‘½ä»¤è¡Œä½¿ç”¨å¸®åŠ©ä¿¡æ¯
USAGE = (
    "-" * 70  # è¾“å‡º70ä¸ªå­—ç¬¦é•¿åº¦çš„æ¨ªçº¿
    + "\n"
    + "| Usage:                                                             |\n"
    + "|   llamafactory-cli api -h: launch an OpenAI-style API server       |\n"  # å¯åŠ¨ç±»ä¼¼OpenAIé£æ ¼çš„APIæœåŠ¡å™¨
    + "|   llamafactory-cli chat -h: launch a chat interface in CLI         |\n"  # å¯åŠ¨å‘½ä»¤è¡ŒèŠå¤©ç•Œé¢
    + "|   llamafactory-cli eval -h: evaluate models                        |\n"  # è¯„ä¼°æ¨¡å‹
    + "|   llamafactory-cli export -h: merge LoRA adapters and export model |\n"  # åˆå¹¶LoRAé€‚é…å™¨å¹¶å¯¼å‡ºæ¨¡å‹
    + "|   llamafactory-cli train -h: train models                          |\n"  # è®­ç»ƒæ¨¡å‹
    + "|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |\n"  # å¯åŠ¨WebèŠå¤©ç•Œé¢
    + "|   llamafactory-cli webui: launch LlamaBoard                        |\n"  # å¯åŠ¨LlamaBoard Webç•Œé¢
    + "|   llamafactory-cli version: show version info                      |\n"  # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    + "-" * 70  # è¾“å‡º70ä¸ªå­—ç¬¦é•¿åº¦çš„æ¨ªçº¿
)

# å®šä¹‰æ¬¢è¿ä¿¡æ¯ï¼ŒåŒ…å«ç‰ˆæœ¬å·å’Œé¡¹ç›®é¡µé¢é“¾æ¥
WELCOME = (
    "-" * 58
    + "\n"
    + "| Welcome to LLaMA Factory, version {}".format(VERSION)  # æ˜¾ç¤ºå½“å‰ç‰ˆæœ¬å·
    + " " * (21 - len(VERSION))
    + "|\n|"
    + " " * 56
    + "|\n"
    + "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n"  # æ˜¾ç¤ºé¡¹ç›®é¡µé¢é“¾æ¥
    + "-" * 58
)

# è·å–æ—¥å¿—è®°å½•å™¨å®ä¾‹
logger = get_logger(__name__)

# å®šä¹‰å‘½ä»¤æšä¸¾ç±»ï¼ŒåŒ…å«å„ç§å¯èƒ½çš„å‘½ä»¤
@unique  # ä½¿ç”¨uniqueè£…é¥°å™¨ç¡®ä¿æšä¸¾å€¼å”¯ä¸€
class Command(str, Enum):
    API = "api"  # å¯åŠ¨APIæœåŠ¡å™¨
    CHAT = "chat"  # å¯åŠ¨èŠå¤©ç•Œé¢
    ENV = "env"  # æ‰“å°ç¯å¢ƒä¿¡æ¯
    EVAL = "eval"  # è¯„ä¼°æ¨¡å‹
    EXPORT = "export"  # å¯¼å‡ºæ¨¡å‹
    TRAIN = "train"  # è®­ç»ƒæ¨¡å‹
    WEBDEMO = "webchat"  # å¯åŠ¨WebèŠå¤©ç•Œé¢
    WEBUI = "webui"  # å¯åŠ¨Web UI
    VER = "version"  # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    HELP = "help"  # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

# å®šä¹‰ä¸»å‡½æ•°ï¼Œè§£æå¹¶æ‰§è¡Œå‘½ä»¤è¡Œè¾“å…¥
def main():
    # ä»å‘½ä»¤è¡Œå‚æ•°ä¸­è·å–å‘½ä»¤ï¼Œå¦‚æœæ²¡æœ‰å‚æ•°ï¼Œåˆ™é»˜è®¤ä¸ºHELPå‘½ä»¤
    command = sys.argv.pop(1) if len(sys.argv) != 1 else Command.HELP
    # æ ¹æ®å‘½ä»¤æ‰§è¡Œå¯¹åº”çš„åŠŸèƒ½
    if command == Command.API:
        run_api()  # å¯åŠ¨APIæœåŠ¡å™¨
    elif command == Command.CHAT:
        run_chat()  # å¯åŠ¨èŠå¤©ç•Œé¢
    elif command == Command.ENV:
        print_env()  # æ‰“å°ç¯å¢ƒä¿¡æ¯
    elif command == Command.EVAL:
        run_eval()  # è¯„ä¼°æ¨¡å‹
    elif command == Command.EXPORT:
        export_model()  # å¯¼å‡ºæ¨¡å‹
    elif command == Command.TRAIN:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶ä½¿ç”¨torchrunè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
        force_torchrun = os.environ.get("FORCE_TORCHRUN", "0").lower() in ["true", "1"]
        # å¦‚æœéœ€è¦ä½¿ç”¨torchrunæˆ–è®¾å¤‡æ•°é‡å¤§äº1ï¼Œåˆ™è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
        if force_torchrun or get_device_count() > 1:
            # è·å–åˆ†å¸ƒå¼è®­ç»ƒæ‰€éœ€çš„ä¸»èŠ‚ç‚¹åœ°å€å’Œç«¯å£
            master_addr = os.environ.get("MASTER_ADDR", "127.0.0.1")
            master_port = os.environ.get("MASTER_PORT", str(random.randint(20001, 29999)))
            logger.info("Initializing distributed tasks at: {}:{}".format(master_addr, master_port))
            # ä½¿ç”¨torchrunå¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡
            process = subprocess.run(
                (
                    "torchrun --nnodes {nnodes} --node_rank {node_rank} --nproc_per_node {nproc_per_node} "
                    "--master_addr {master_addr} --master_port {master_port} {file_name} {args}"
                ).format(
                    nnodes=os.environ.get("NNODES", "1"),  # è·å–èŠ‚ç‚¹æ•°é‡
                    node_rank=os.environ.get("RANK", "0"),  # è·å–èŠ‚ç‚¹æ’å
                    nproc_per_node=os.environ.get("NPROC_PER_NODE", str(get_device_count())),  # è·å–æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹æ•°é‡
                    master_addr=master_addr,  # ä½¿ç”¨çš„ä¸»èŠ‚ç‚¹åœ°å€
                    master_port=master_port,  # ä½¿ç”¨çš„ä¸»èŠ‚ç‚¹ç«¯å£
                    file_name=launcher.__file__,  # å¯åŠ¨çš„æ–‡ä»¶å
                    args=" ".join(sys.argv[1:]),  # ä¼ é€’ç»™torchrunçš„é¢å¤–å‚æ•°
                ),
                shell=True,  # åœ¨shellä¸­è¿è¡Œå‘½ä»¤
            )
            sys.exit(process.returncode)  # é€€å‡ºå¹¶è¿”å›å­è¿›ç¨‹çš„é€€å‡ºçŠ¶æ€
        else:
            run_exp()  # å¯åŠ¨å•èŠ‚ç‚¹è®­ç»ƒ
    elif command == Command.WEBDEMO:
        run_web_demo()  # å¯åŠ¨Webæ¼”ç¤ºç•Œé¢
    elif command == Command.WEBUI:
        run_web_ui()  # å¯åŠ¨Web UIç•Œé¢
    elif command == Command.VER:
        print(WELCOME)  # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯å’Œç‰ˆæœ¬å·
    elif command == Command.HELP:
        print(USAGE)  # æ˜¾ç¤ºä½¿ç”¨å¸®åŠ©ä¿¡æ¯
    else:
        raise NotImplementedError("Unknown command: {}".format(command))  # æŠ›å‡ºæœªå®ç°çš„å‘½ä»¤é”™è¯¯
```

ä» `llamafactory/cli.py` æ–‡ä»¶çš„ä»£ç å¯ä»¥çœ‹å‡ºï¼Œ`llamafactory-cli` å‘½ä»¤è¡Œå·¥å…·çš„ä¸»è¦é€»è¾‘å°±æ˜¯è§£æç”¨æˆ·è¾“å…¥çš„å‘½ä»¤ï¼Œå¹¶æ ¹æ®ä¸åŒçš„å‘½ä»¤è°ƒç”¨ç›¸åº”çš„å‡½æ•°æ¥æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡ã€‚

ä¸‹é¢æ˜¯ä¸€äº›å…³é”®ç‚¹çš„è§£é‡Š:

### å…³é”®ç»„ä»¶:

1. **å‘½ä»¤æšä¸¾ (`Command` Enum)**:
    
    - `Command` æ˜¯ä¸€ä¸ªæšä¸¾ç±»ï¼Œå®šä¹‰äº†æ‰€æœ‰å¯ä»¥é€šè¿‡ `llamafactory-cli` ä½¿ç”¨çš„å‘½ä»¤ï¼ŒåŒ…æ‹¬ `api`ã€`chat`ã€`eval`ã€`export`ã€`train`ã€`webchat`ã€`webui` ç­‰ã€‚

2. **`main` å‡½æ•°**:
    
    - `main` å‡½æ•°æ˜¯å‘½ä»¤è¡Œå·¥å…·çš„å…¥å£ç‚¹ï¼Œè´Ÿè´£è§£æç”¨æˆ·è¾“å…¥çš„å‘½ä»¤å¹¶æ ¹æ®ç›¸åº”çš„å‘½ä»¤æ‰§è¡Œå¯¹åº”çš„åŠŸèƒ½ã€‚
    
    - `sys.argv.pop(1)` è·å–å‘½ä»¤è¡Œä¸­çš„ç¬¬ä¸€ä¸ªå‚æ•°ä½œä¸ºå‘½ä»¤ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥å‘½ä»¤åˆ™é»˜è®¤ä½¿ç”¨ `Command.HELP`ï¼ˆå³å¸®åŠ©ä¿¡æ¯ï¼‰ã€‚
    
    - æ ¹æ®è§£æå‡ºçš„å‘½ä»¤ï¼Œ`main` å‡½æ•°ä¼šè°ƒç”¨ä¸åŒçš„å‡½æ•°ï¼Œä¾‹å¦‚ `run_api()` å¯åŠ¨ API æœåŠ¡å™¨ï¼Œ`run_web_ui()` å¯åŠ¨ `webui` ç•Œé¢ç­‰ã€‚

3. **å‘½ä»¤çš„å®ç°**:

    - æ¯ä¸ªå‘½ä»¤èƒŒåéƒ½æœ‰å¯¹åº”çš„å‡½æ•°ï¼Œæ¯”å¦‚:

        - `Command.WEBUI` å¯¹åº” `run_web_ui()`ï¼Œå¯åŠ¨ Web ç•Œé¢ã€‚

        - `Command.TRAIN` å¯¹åº” `run_exp()` æˆ– `torchrun` åˆ†å¸ƒå¼è®­ç»ƒä»»åŠ¡ã€‚

        - `Command.VER` æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯ã€‚

    - å¦‚æœä½ æƒ³æŸ¥çœ‹æ¯ä¸ªå­å‘½ä»¤å…·ä½“åšäº†ä»€ä¹ˆï¼Œå¯ä»¥æ·±å…¥åˆ°è¿™äº›å­å‘½ä»¤æ‰€å¯¹åº”çš„å‡½æ•°ï¼ˆå¦‚ `run_web_ui()`ï¼‰çš„å®ç°æ–‡ä»¶ä¸­å»ã€‚


## ä¸¾ä¾‹-ç»ˆç«¯è¿è¡Œ`llamafactory-cli help`:

è®²äº†é‚£ä¹ˆå¤šï¼Œç°åœ¨ä¸ºä»£ç æ·»åŠ ä¸€ä¸‹ `print`ï¼ŒéªŒè¯ä¸‹å‰é¢è®²çš„å†…å®¹ã€‚è¯»è€…å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼ä¿®æ”¹ `llamafactory/cli.py` ä¸­çš„ä»£ç :

```python
# llamafactory/cli.py

# å…¶ä»–ä»£ç çœç•¥

def main():
    print(f"sys.argvä¸º:{sys.argv}")
    pop_value = sys.argv.pop(1)
    print(f"sys.argv.pop(1)ä¸º:{pop_value}ï¼Œç±»å‹:{type(pop_value)}")
    
    command = sys.argv.pop(1) if len(sys.argv) != 1 else Command.HELP
    # å…¶ä»–ä»£ç çœç•¥
```

å½“ç»ˆç«¯è¿è¡Œ`llamafactory-cli help`æ—¶:

```log
(myenv) root@ubuntu22:/data/LLaMA-Factory-main# llamafactory-cli help
sys.argvä¸º:['/home/vipuser/miniconda3/envs/myenv/bin/llamafactory-cli', 'help']
sys.argv.pop(1)ä¸º:helpï¼Œç±»å‹:<class 'str'>
----------------------------------------------------------------------
| Usage:                                                             |
|   llamafactory-cli api -h: launch an OpenAI-style API server       |
|   llamafactory-cli chat -h: launch a chat interface in CLI         |
|   llamafactory-cli eval -h: evaluate models                        |
|   llamafactory-cli export -h: merge LoRA adapters and export model |
|   llamafactory-cli train -h: train models                          |
|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |
|   llamafactory-cli webui: launch LlamaBoard                        |
|   llamafactory-cli version: show version info                      |
----------------------------------------------------------------------
(myenv) root@ubuntu22:/data/LLaMA-Factory-main# 
```

ä»ä»£ç ä¸­å¯ä»¥çœ‹å‡ºï¼Œè§¦å‘äº†ä¸‹åˆ—é€»è¾‘:

```python
# å…¶ä»–ä»£ç çœç•¥
    elif command == Command.HELP:
        print(USAGE)  # æ˜¾ç¤ºä½¿ç”¨å¸®åŠ©ä¿¡æ¯
# å…¶ä»–ä»£ç çœç•¥
```


## é™„å½•: sys.argv ç”¨æ³•è§£é‡Š

`sys.argv` æ˜¯ä¸€ä¸ªåŒ…å«å‘½ä»¤è¡Œå‚æ•°çš„åˆ—è¡¨ï¼Œå…¶ä¸­ï¼š

- `sys.argv[0]` æ˜¯è„šæœ¬çš„åç§°æˆ–å‘½ä»¤åï¼ˆå¦‚ `llamafactory-cli`ï¼‰ã€‚

- `sys.argv[1]` åŠä¹‹åçš„å…ƒç´ æ˜¯ä¼ é€’ç»™è„šæœ¬çš„å‚æ•°ã€‚

`sys.argv.pop(1)` çš„ä½œç”¨æ˜¯ä»å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨ `sys.argv` ä¸­ç§»é™¤å¹¶è¿”å›ç´¢å¼•ä¸º `1` çš„å…ƒç´ ã€‚

ä¾‹å¦‚ä½ åœ¨ç»ˆç«¯è¾“å…¥ä¸‹åˆ—æŒ‡ä»¤(è¿™ä¸ªå‘½ä»¤æ˜¯ç¬”è€…è™šæ„çš„):

```bash
llamafactory-cli webui --port 8080
```

åˆ™ `sys.argv` åˆ—è¡¨çš„å†…å®¹å¦‚ä¸‹ï¼š

```python
sys.argv = ['llamafactory-cli', 'webui', '--port', '8080']
```

è°ƒç”¨ `sys.argv.pop(1)` åï¼Œ`sys.argv` å‘ç”Ÿä»¥ä¸‹å˜åŒ–ï¼š

- **è¿”å›å€¼**ï¼š`'webui'`ï¼ˆå› ä¸ºè¿™æ˜¯ç´¢å¼•ä¸º `1` çš„å…ƒç´ ï¼‰

- **ä¿®æ”¹åçš„ `sys.argv` åˆ—è¡¨**ï¼š

```python
sys.argv = ['llamafactory-cli', '--port', '8080']
```